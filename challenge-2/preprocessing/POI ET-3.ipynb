{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "accomplished-squad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Settings\n",
    "pd.set_option('max_colwidth', 80)\n",
    "pd.options.display.max_rows = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "golden-child",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "tr = pd.read_csv('../train.csv')\n",
    "te = pd.read_csv('../test.csv')\n",
    "\n",
    "# Get POI and street\n",
    "tr['poi'] = tr['POI/street'].str.split('/', expand=True)[0]\n",
    "tr['poi_list'] = tr.poi.apply(str.split)\n",
    "\n",
    "# Get rows with extended words\n",
    "tr['poi_ext'] = tr.apply(lambda row: not row['poi'] in row['raw_address'], axis=1)\n",
    "tr['raw_list'] = tr.raw_address.str.split()\n",
    "\n",
    "# Save in separate dataframes\n",
    "# df_poi = tr[tr.poi_ext].copy().drop(['poi_ext', 'POI/street'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "mobile-order",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove punctuation\n",
    "def remove_punc(s):\n",
    "    exclude = set(string.punctuation)\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    return s.translate(table)\n",
    "\n",
    "# Function to check keywords\n",
    "def check_keyword(l, kw, top):\n",
    "    exclude = [w for w in top if w != kw]\n",
    "    \n",
    "    if kw in l:\n",
    "        for exc in exclude:\n",
    "            if exc in l:\n",
    "                return False\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-pointer",
   "metadata": {},
   "source": [
    "## Points of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "whole-favor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract tokens\n",
    "# df_poi['raw_list'] = df_poi.raw_address.apply(lambda x: [remove_punc(str(i)) for i in x.split(' ')])\n",
    "# df_poi['poi_list'] = df_poi.poi.apply(lambda x: [remove_punc(str(i)) for i in x.split(' ')])\n",
    "# df_poi['super_raw'] = df_poi.raw_address.apply(str.split)\n",
    "\n",
    "df_poi = tr.copy().drop(['poi_ext', 'POI/street'], axis=1)\n",
    "df_poi['raw_list'] = df_poi.raw_address.apply(lambda x: [remove_punc(str(i)) for i in x.split(' ')])\n",
    "df_poi['raw_list_orig'] = df_poi.raw_address.apply(str.split)\n",
    "df_poi['poi_list'] = df_poi.poi.apply(lambda x: [remove_punc(str(i)) for i in x.split(' ')])\n",
    "df_poi['poi_list_orig'] = df_poi.poi.apply(str.split)\n",
    "df_poi['super_raw'] = df_poi.raw_address.apply(str.split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "overall-farmer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15e19286146e4e8b9a29be3b4fb6ca79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_words = []\n",
    "all_phrases = []\n",
    "\n",
    "for i in tqdm(range(df_poi.shape[0])):\n",
    "    x1 = df_poi.raw_list.iloc[i]\n",
    "    x2 = df_poi.poi_list.iloc[i]\n",
    "    x_orig = df_poi.raw_list_orig.iloc[i]\n",
    "    x_ext = df_poi.poi_list_orig.iloc[i]\n",
    "    \n",
    "    match_scores = []\n",
    "    ids = []\n",
    "    for j in range(0, len(x1)-len(x2)+1):\n",
    "        start = j\n",
    "        end = j+len(x2)\n",
    "        ids.append((start, end))\n",
    "        \n",
    "        scores = []\n",
    "        for s1, s2 in zip(x1[start:end], x2):\n",
    "            scores.append(SequenceMatcher(None, s1, s2).ratio())\n",
    "        match_scores.append(np.mean(scores))\n",
    "\n",
    "    opt = np.argmax(match_scores)\n",
    "\n",
    "    matched_seq = x1[ids[opt][0]:ids[opt][1]]\n",
    "    \n",
    "    \n",
    "    all_phrases.append({\n",
    "        'idx': df_poi.id.iloc[i],\n",
    "        'raw': df_poi.super_raw.iloc[i],\n",
    "        'orig': matched_seq,\n",
    "        'repl': x2\n",
    "    })\n",
    "    \n",
    "    for k, m in enumerate(matched_seq):\n",
    "#         if m != x2[k]:\n",
    "        all_words.append({\n",
    "            'orig': m,\n",
    "            'repl': x2[k],\n",
    "#             'orig_main': x_orig[k],\n",
    "#             'ext_main': x_ext[k]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "together-bacon",
   "metadata": {},
   "outputs": [],
   "source": [
    "poip = pd.DataFrame(all_phrases).sort_values('orig').reset_index(drop=True)\n",
    "poiw = pd.DataFrame(all_words).sort_values('orig').reset_index(drop=True)\n",
    "\n",
    "poip['orig_full'] = poip.orig.apply(lambda x: ' '.join(x))\n",
    "poip['repl_full'] = poip.repl.apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suffering-registrar",
   "metadata": {},
   "source": [
    "## Programmatic Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "affecting-idaho",
   "metadata": {},
   "outputs": [],
   "source": [
    "poiw = poiw[poiw.repl != '']\n",
    "\n",
    "# Get dictionary\n",
    "poiw_ext = poiw[poiw.orig != poiw.repl]\n",
    "\n",
    "# Filter only words that were extended\n",
    "df_ext = poiw.groupby('orig').count()\n",
    "df_ext['unique_ext'] = poiw.groupby('orig').repl.nunique()\n",
    "df_ext = df_ext[df_ext.unique_ext>1].reset_index()\n",
    "\n",
    "# Count extensions and non-extensions\n",
    "ext = poiw[poiw.orig != poiw.repl].groupby('orig').count()\n",
    "no_ext = poiw[poiw.orig == poiw.repl].groupby('orig').count()\n",
    "\n",
    "# Merge extensions and non-extensions\n",
    "df_ext = df_ext.merge(ext, how='left', left_on='orig', right_index=True).rename(columns={'orig': 'word', 'repl_x': 'count', 'repl_y': 'ext'})\n",
    "df_ext = df_ext.merge(no_ext, how='left', left_on='word', right_index=True).rename(columns={'repl': 'no_ext'})\n",
    "\n",
    "# Fill 0 for non-extensions\n",
    "df_ext['no_ext'] = df_ext.no_ext.fillna(0)\n",
    "\n",
    "# Compute extension rate\n",
    "df_ext['ext_rate'] = df_ext.ext / df_ext['count']\n",
    "\n",
    "# Filter and sort\n",
    "df_ext = df_ext[df_ext.word != '']\n",
    "# df_ext = df_ext[(df_ext.ext_rate > 0.6) & (df_ext['count'] >= 5)].sort_values('count', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "single-kruger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebb3fd6b37744b12978f62bc1c421e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "replacements = []\n",
    "for word in tqdm(df_ext.word):\n",
    "    freqs = poiw_ext[poiw_ext.orig == word].repl.value_counts()\n",
    "    probs = freqs / freqs.sum()\n",
    "    replacements.append({'word': word, 'ext': freqs.index[0], 'prob': probs.values[0], 'freq': freqs.values[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "classified-liechtenstein",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>unique_ext</th>\n",
       "      <th>n_ext</th>\n",
       "      <th>no_ext</th>\n",
       "      <th>ext_rate</th>\n",
       "      <th>ext</th>\n",
       "      <th>prob</th>\n",
       "      <th>freq</th>\n",
       "      <th>net</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acad</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>academy</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acces</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>accesoris</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>access</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>accessories</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>24</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ach</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>achmad</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>12</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adip</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>adipura</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>yaya</td>\n",
       "      <td>160</td>\n",
       "      <td>2</td>\n",
       "      <td>158</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.987500</td>\n",
       "      <td>yayasan</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>158</td>\n",
       "      <td>156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1161</th>\n",
       "      <td>yoha</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>yohanes</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>zaen</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>zaenuri</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>zai</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>zaitun</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>zid</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>zidane</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1165 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        word  count  unique_ext  n_ext  no_ext  ext_rate          ext  \\\n",
       "0       acad      5           2      5     0.0  1.000000      academy   \n",
       "1      acces      4           2      3     1.0  0.750000    accesoris   \n",
       "2     access     30           4     27     3.0  0.900000  accessories   \n",
       "3        ach     17           3     14     3.0  0.823529       achmad   \n",
       "4       adip      6           3      6     0.0  1.000000      adipura   \n",
       "...      ...    ...         ...    ...     ...       ...          ...   \n",
       "1160    yaya    160           2    158     2.0  0.987500      yayasan   \n",
       "1161    yoha      4           2      3     1.0  0.750000      yohanes   \n",
       "1162    zaen      6           3      5     1.0  0.833333      zaenuri   \n",
       "1163     zai     17           7     16     1.0  0.941176       zaitun   \n",
       "1164     zid      4           2      4     0.0  1.000000       zidane   \n",
       "\n",
       "          prob  freq    net  \n",
       "0     0.800000     4    4.0  \n",
       "1     1.000000     3    2.0  \n",
       "2     0.888889    24   21.0  \n",
       "3     0.857143    12    9.0  \n",
       "4     0.500000     3    3.0  \n",
       "...        ...   ...    ...  \n",
       "1160  1.000000   158  156.0  \n",
       "1161  1.000000     3    2.0  \n",
       "1162  0.600000     3    2.0  \n",
       "1163  0.312500     5    4.0  \n",
       "1164  0.750000     3    3.0  \n",
       "\n",
       "[1165 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add extension, probability, and frequency\n",
    "df_ext_probs = df_ext.merge(pd.DataFrame(replacements), how='left', on='word').rename(columns={'ext_x': 'n_ext', 'ext_y': 'ext'})\n",
    "\n",
    "# Calculate net gain\n",
    "df_ext_probs['net'] = df_ext_probs.n_ext * df_ext_probs.prob - df_ext_probs.no_ext\n",
    "\n",
    "# Inspect\n",
    "df_ext_filtered = df_ext_probs[(df_ext_probs.net > 0) & (df_ext_probs.freq > 2)].reset_index(drop=True)\n",
    "df_ext_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serial-poker",
   "metadata": {},
   "source": [
    "### Final Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "forty-alert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ef6c719e0d4fc58e2ea20e2de6c63e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 alhasanah\n",
      "25 alikhlas\n",
      "26 alikhlash\n",
      "30 almubarokah\n"
     ]
    }
   ],
   "source": [
    "replace_checks = []\n",
    "\n",
    "# Check extensions\n",
    "for i, word in enumerate(tqdm(df_ext_filtered[df_ext_filtered.net > 0].ext)):\n",
    "    if tr.poi.str.contains(word).sum() == 0:\n",
    "        print(i, word)\n",
    "        replace_checks.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "documentary-trader",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                      293733\n",
       "raw_address           mas al-has teh 10, no 46\n",
       "POI/street            masjid al-hasanah/teh 10\n",
       "poi                          masjid al-hasanah\n",
       "poi_list                  [masjid, al-hasanah]\n",
       "poi_ext                                   True\n",
       "raw_list       [mas, al-has, teh, 10,, no, 46]\n",
       "Name: 293733, dtype: object"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr.loc[poip[poip.repl.apply(lambda x: 'alhasanah' in x)].idx.iloc[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "adult-robinson",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ext_filtered.loc[23, 'word'] = 'al-has'\n",
    "df_ext_filtered.loc[23, 'ext'] = 'al-hasanah'\n",
    "\n",
    "df_ext_filtered.loc[25, 'word'] = 'al-ik'\n",
    "df_ext_filtered.loc[25, 'ext'] = 'al-ikhlas'\n",
    "\n",
    "df_ext_filtered.loc[26, 'word'] = 'al-ikh'\n",
    "df_ext_filtered.loc[26, 'ext'] = 'al-ikhlas'\n",
    "\n",
    "df_ext_filtered.loc[30, 'word'] = 'al-muba'\n",
    "df_ext_filtered.loc[30, 'ext'] = 'al-mubarokah'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resistant-rescue",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ext_filter.to_csv('poi_et-3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
